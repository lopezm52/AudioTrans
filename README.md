# AudioTrans API

Una aplicaci√≥n de transcripci√≥n de audio que utiliza OpenAI Whisper para transcribir archivos .m4a y OpenAI GPT para procesar las transcripciones.

## Caracter√≠sticas

- üéµ **Soporte para archivos .m4a**: Acepta archivos de audio en formato M4A
- ‚ö° **Procesamiento en segmentos**: Divide autom√°ticamente archivos largos en segmentos de 5 minutos
- ü§ñ **Transcripci√≥n con Whisper**: Utiliza el modelo "small" de OpenAI Whisper ejecutado localmente (configurable)
- üìù **Procesamiento inteligente**: Procesa las transcripciones con OpenAI GPT para mejorar y analizar el contenido
- üîê **Autenticaci√≥n con API Key**: Protecci√≥n mediante API Key fija
- üê≥ **Docker Ready**: Completamente containerizada
- ‚ö° **Manejo robusto de errores**: Recuperaci√≥n autom√°tica y logging detallado
- üîß **Configuraci√≥n flexible**: Variables de entorno desde archivo .env
- üìä **Health check completo**: Monitoreo de estado y configuraci√≥n

## Requisitos Previos

- Docker y Docker Compose instalados
- API Key de OpenAI (para el procesamiento con GPT)

## Instalaci√≥n y Configuraci√≥n

### 1. Clonar o crear el proyecto

```bash
mkdir audiotrans && cd audiotrans
# Copiar todos los archivos del proyecto aqu√≠
```

### 2. Configurar variables de entorno

**Opci√≥n A: Usar archivo .env (Recomendado)**
```bash
# Copiar archivo de ejemplo
cp env.example .env

# Luego edita .env con tus valores reales
nano .env
```

**Opci√≥n B: Variables de entorno del sistema**
```bash
export API_KEY="tu-api-key-aqui"
export OPENAI_API_KEY="tu-openai-key-aqui"
export WHISPER_MODEL="small"
export MAX_FILE_SIZE="100MB"
```

**Contenido del archivo `.env`:**
```bash
# API Key fija para autenticaci√≥n de la aplicaci√≥n
API_KEY=audio-trans-secret-key-2024

# Tu API Key de OpenAI (obligatoria)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Configuraciones adicionales
WHISPER_MODEL=small        # tiny, base, small, medium, large
MAX_FILE_SIZE=100MB       # Tama√±o m√°ximo de archivo (KB, MB, GB)
```

**Importante**: La aplicaci√≥n carga autom√°ticamente las variables desde el archivo `.env`.

### 3. Verificar configuraci√≥n (Opcional)

```bash
# Ejecutar script de verificaci√≥n
python verify_setup.py
```

### 4. Construir y ejecutar con Docker Compose

```bash
# Construir y ejecutar la aplicaci√≥n
docker-compose up --build

# O ejecutar en segundo plano
docker-compose up -d --build
```

La aplicaci√≥n estar√° disponible en: http://localhost:8000

## Uso de la API

### Endpoints Disponibles

#### 1. Health Check
```bash
GET /health
```

Verifica el estado de la aplicaci√≥n y muestra la configuraci√≥n actual:

```json
{
  "status": "healthy",
  "whisper_model_loaded": true,
  "whisper_model": "small",
  "max_file_size_mb": 100.0,
  "api_key_configured": true,
  "openai_key_configured": true
}
```

#### 2. Transcripci√≥n de Audio
```bash
POST /transcribe
```

**Headers obligatorios:**
```
X-API-Key: audio-trans-secret-key-2024
Content-Type: multipart/form-data
```

**Par√°metros:**
- `file`: Archivo de audio en formato .m4a (obligatorio)
- `custom_prompt`: Prompt personalizado para el procesamiento con OpenAI (opcional)

### Ejemplo de uso con cURL

```bash
curl -X POST "http://localhost:8000/transcribe" \
     -H "X-API-Key: audio-trans-secret-key-2024" \
     -F "file=@tu-archivo.m4a" \
     -F "custom_prompt=Analiza esta transcripci√≥n y extrae los puntos clave"
```

### Ejemplo de uso con Python

```python
import requests

url = "http://localhost:8000/transcribe"
headers = {"X-API-Key": "audio-trans-secret-key-2024"}

files = {"file": open("tu-archivo.m4a", "rb")}
data = {"custom_prompt": "Analiza esta transcripci√≥n y proporciona un resumen"}

response = requests.post(url, headers=headers, files=files, data=data)
print(response.json())
```

## Respuesta de la API

La API devuelve un JSON con la siguiente estructura:

```json
{
  "status": "success",
  "original_filename": "audio.m4a",
  "segments_processed": 3,
  "transcription_length": 1250,
  "raw_transcription": "Transcripci√≥n completa del audio...",
  "processed_response": "An√°lisis procesado por OpenAI GPT...",
  "message": "Audio transcrito y procesado exitosamente"
}
```

## Proceso de Transcripci√≥n

1. **Recepci√≥n**: La API recibe el archivo .m4a
2. **Segmentaci√≥n**: El audio se divide en fragmentos de 5 minutos
3. **Transcripci√≥n**: Cada segmento se transcribe usando Whisper (modelo medium)
4. **Uni√≥n**: Las transcripciones se unen manteniendo el orden correcto
5. **Procesamiento**: El texto completo se env√≠a a OpenAI GPT para an√°lisis
6. **Respuesta**: Se devuelve tanto la transcripci√≥n original como el an√°lisis procesado

## Configuraci√≥n Avanzada

### Variables de Entorno

| Variable | Descripci√≥n | Valor por Defecto | Ejemplo |
|----------|-------------|-------------------|---------|
| `API_KEY` | API Key para autenticaci√≥n | `audio-trans-secret-key-2024` | `mi-clave-secreta` |
| `OPENAI_API_KEY` | API Key de OpenAI | *Requerida* | `sk-proj-abc123...` |
| `WHISPER_MODEL` | Modelo de Whisper a usar | `small` | `medium`, `large` |
| `MAX_FILE_SIZE` | Tama√±o m√°ximo de archivo | `100MB` | `50MB`, `1GB`, `500KB` |

### Modelos de Whisper Disponibles

La aplicaci√≥n carga el modelo configurado en `WHISPER_MODEL` desde el archivo `.env`:

| Modelo | Precisi√≥n | Velocidad | Uso de RAM | Recomendado para |
|--------|-----------|-----------|------------|-------------------|
| `tiny` | B√°sica | Muy r√°pida | ~39MB | Pruebas r√°pidas |
| `base` | Buena | R√°pida | ~74MB | Desarrollo |
| `small` | Muy buena | Media | ~244MB | **Pruebas (por defecto)** |
| `medium` | Excelente | Lenta | ~769MB | **Producci√≥n** |
| `large` | M√°xima | Muy lenta | ~1550MB | Casos cr√≠ticos |

Para cambiar el modelo, simplemente edita el archivo `.env`:
```bash
# Cambiar a modelo m√°s preciso
WHISPER_MODEL=medium

# O a modelo m√°s r√°pido
WHISPER_MODEL=tiny
```

Luego reconstruye el contenedor: `docker-compose up --build`

### Manejo de Errores y Recuperaci√≥n

La aplicaci√≥n incluye manejo robusto de errores:

- **Transcripci√≥n parcial**: Si algunos segmentos fallan, contin√∫a con los exitosos
- **Modelo de respaldo**: Si el modelo especificado falla, usa "small" autom√°ticamente
- **Validaci√≥n de archivos**: Verifica formato y tama√±o antes de procesar
- **Limpieza autom√°tica**: Elimina archivos temporales incluso si hay errores
- **Logging detallado**: Informaci√≥n completa para debugging

### Personalizaci√≥n del Prompt

Puedes personalizar c√≥mo OpenAI procesa las transcripciones enviando un `custom_prompt`:

```bash
curl -X POST "http://localhost:8000/transcribe" \
     -H "X-API-Key: audio-trans-secret-key-2024" \
     -F "file=@audio.m4a" \
     -F "custom_prompt=Extrae las tareas mencionadas y crea una lista numerada"
```

## Monitoreo y Logs

Para ver los logs en tiempo real:

```bash
docker-compose logs -f audiotrans
```

## Limitaciones

- Solo acepta archivos en formato .m4a
- Uso de RAM variable seg√∫n el modelo Whisper seleccionado (ver tabla de modelos)
- Tama√±o de archivo limitado por `MAX_FILE_SIZE` (100MB por defecto, configurable)
- Los archivos muy largos pueden tomar tiempo considerable en procesarse
- L√≠mite de tokens de OpenAI GPT (4000 tokens por defecto)

## Soluci√≥n de Problemas

### Error: "Modelo Whisper no est√° disponible"
- Verifica que el contenedor tenga suficiente memoria RAM
- Revisa los logs para ver si hay errores en la carga del modelo

### Error: "API Key inv√°lida"
- Verifica que est√©s enviando el header `X-API-Key` correcto
- Confirma que el valor coincida con la variable de entorno `API_KEY`

### Error: "OpenAI API Key no configurada"
- Verifica que hayas configurado `OPENAI_API_KEY` en tu archivo `.env`
- Confirma que la API Key de OpenAI sea v√°lida y tenga cr√©ditos

### Error: "Archivo demasiado grande"
- El archivo excede el l√≠mite configurado en `MAX_FILE_SIZE`
- Puedes aumentar el l√≠mite editando `.env`: `MAX_FILE_SIZE=200MB`
- O comprimir/dividir el archivo de audio antes de subirlo

### Error cargando modelo Whisper
- Verifica que el modelo especificado en `WHISPER_MODEL` sea v√°lido
- Modelos v√°lidos: `tiny`, `base`, `small`, `medium`, `large`
- La aplicaci√≥n intentar√° cargar el modelo "small" como respaldo

## Desarrollo

Para desarrollar localmente:

```bash
# Instalar dependencias
pip install -r requirements.txt

# Ejecutar la aplicaci√≥n
python app.py
```

## Seguridad

- Cambia la `API_KEY` por defecto en producci√≥n
- Mant√©n tu `OPENAI_API_KEY` segura y no la commits al control de versiones
- Considera implementar rate limiting para APIs p√∫blicas

## Licencia

Este proyecto es de c√≥digo abierto. √ösalo bajo tu propia responsabilidad. 